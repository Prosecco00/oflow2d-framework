{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64krXMUc2ksG"
   },
   "outputs": [],
   "source": [
    "# Reset pulito (opzionale)\n",
    "!rm -rf /content/RAFT /content/oflow2d /content/outputs\n",
    "\n",
    "# Dipendenze base (torch è già in Colab)\n",
    "!pip -q install opencv-python tqdm matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2j0xIdgs2kp_",
    "outputId": "274fb47a-65e6-4c03-b77d-487ce4611b4f"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/princeton-vl/RAFT /content/RAFT\n",
    "%cd /content/RAFT\n",
    "!bash download_models.sh\n",
    "%cd /content\n",
    "\n",
    "# Verifica file essenziali\n",
    "import os\n",
    "for p in [\n",
    "    \"/content/RAFT/models/raft-small.pth\",\n",
    "    \"/content/RAFT/models/raft-sintel.pth\",\n",
    "    \"/content/RAFT/core/raft.py\",\n",
    "    \"/content/RAFT/core/utils/utils.py\",\n",
    "]:\n",
    "    print((\"✓\" if os.path.exists(p) else \"✗\"), p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89OSCOHo2kn-",
    "outputId": "0c4f852d-15d3-4ca9-c2ed-d552822571ea"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, pathlib, textwrap\n",
    "base = pathlib.Path(\"/content/oflow2d\")\n",
    "(base/\"common\").mkdir(parents=True, exist_ok=True)\n",
    "(base/\"adapters\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# __init__.py\n",
    "(base/\"__init__.py\").write_text(\"__all__=['common','adapters']\\n\")\n",
    "\n",
    "# common/utils.py\n",
    "(base/\"common\"/\"utils.py\").write_text(textwrap.dedent(\"\"\"\n",
    "import cv2, numpy as np\n",
    "\n",
    "def load_video_frames(video_path, max_frames=None, stride=1):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    assert cap.isOpened(), f'Impossibile aprire {video_path}'\n",
    "    frames, i = [], 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "        if i % stride == 0:\n",
    "            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            if max_frames and len(frames) >= max_frames: break\n",
    "        i += 1\n",
    "    cap.release()\n",
    "    if len(frames) < 2: raise RuntimeError(\"Servono almeno 2 frame nel video.\")\n",
    "    return frames\n",
    "\n",
    "def pairwise(frames):\n",
    "    for i in range(len(frames)-1):\n",
    "        yield frames[i], frames[i+1]\n",
    "\"\"\"))\n",
    "\n",
    "# common/viz.py\n",
    "(base/\"common\"/\"viz.py\").write_text(textwrap.dedent(\"\"\"\n",
    "import numpy as np, cv2\n",
    "def flow_to_color(flow, clip_flow=None):\n",
    "    fx = flow[...,0]; fy = flow[...,1]\n",
    "    rad = (fx**2 + fy**2) ** 0.5\n",
    "    ang = np.arctan2(fy, fx)\n",
    "    if clip_flow is not None: rad = np.clip(rad, 0, clip_flow)\n",
    "    rad_n = (rad - rad.min()) / (rad.max() - rad.min() + 1e-8)\n",
    "    ang_n = (ang + np.pi) / (2*np.pi)\n",
    "    hsv = np.zeros((*flow.shape[:2],3), dtype=np.float32)\n",
    "    hsv[...,0] = ang_n * 179.0; hsv[...,1] = 1.0; hsv[...,2] = rad_n\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return (bgr[:,:,::-1]*255.0).astype('uint8')\n",
    "\"\"\"))\n",
    "\n",
    "# common/metrics.py (se userai GT)\n",
    "(base/\"common\"/\"metrics.py\").write_text(textwrap.dedent(\"\"\"\n",
    "import numpy as np\n",
    "def epe(pred, gt, valid_mask=None):\n",
    "    diff = pred - gt\n",
    "    dist = np.sqrt((diff**2).sum(axis=-1))\n",
    "    if valid_mask is not None: dist = dist[valid_mask>0]\n",
    "    return float(dist.mean()) if dist.size>0 else float('nan')\n",
    "\n",
    "def fl_all(pred, gt, tau=3.0, valid_mask=None):\n",
    "    diff = pred - gt\n",
    "    dist = np.sqrt((diff**2).sum(axis=-1))\n",
    "    if valid_mask is not None: dist = dist[valid_mask>0]\n",
    "    if dist.size==0: return float('nan')\n",
    "    return float((dist>tau).mean()*100.0)\n",
    "\n",
    "def angular_error(pred, gt, eps=1e-6, valid_mask=None):\n",
    "    px,py = pred[...,0], pred[...,1]\n",
    "    gx,gy = gt[...,0], gt[...,1]\n",
    "    pnorm = np.sqrt(px*px+py*py)+eps\n",
    "    gnorm = np.sqrt(gx*gx+gy*gy)+eps\n",
    "    dot = (px*gx+py*gy)/(pnorm*gnorm)\n",
    "    dot = np.clip(dot,-1,1)\n",
    "    ang = np.degrees(np.arccos(dot))\n",
    "    if valid_mask is not None: ang = ang[valid_mask>0]\n",
    "    return float(ang.mean()) if ang.size>0 else float('nan')\n",
    "\"\"\"))\n",
    "\n",
    "# adapters/__init__.py\n",
    "(base/\"adapters\"/\"__init__.py\").write_text(textwrap.dedent(\"\"\"\n",
    "def make_model(name:str, **kwargs):\n",
    "    name = name.lower()\n",
    "    if name == 'raft':\n",
    "        from .raft import RAFTAdapter\n",
    "        return RAFTAdapter(**kwargs)\n",
    "    raise ValueError(f\"Modello '{name}' non supportato. Usa 'raft'.\")\n",
    "\"\"\"))\n",
    "\n",
    "# adapters/raft.py — robusto: RAFT-small+FP16, niente alt_cuda_corr, pesi con/ senza 'module.'\n",
    "(base/\"adapters\"/\"raft.py\").write_text(textwrap.dedent(\"\"\"\n",
    "import os, sys, torch, numpy as np\n",
    "\n",
    "class _DotArgs(dict):\n",
    "    __getattr__ = dict.get\n",
    "    def __setattr__(self, k, v): self[k] = v\n",
    "    def __contains__(self, k): return dict.__contains__(self, k)\n",
    "\n",
    "class RAFTAdapter:\n",
    "    def __init__(self, weights:str, device:str=None,\n",
    "                 small:bool=True, mixed_precision:bool=True, alternate_corr:bool=False):\n",
    "        raft_root = os.environ.get(\"RAFT_ROOT\", \"/content/RAFT\")\n",
    "        core_path = os.path.join(raft_root, \"core\")\n",
    "        for p in (core_path, raft_root):\n",
    "            if p not in sys.path: sys.path.insert(0, p)\n",
    "\n",
    "        try:\n",
    "            from core.raft import RAFT as RAFTCore\n",
    "            from core.utils.utils import InputPadder\n",
    "        except Exception as e:\n",
    "            raise ImportError(\"RAFT non trovato. Aggiungi /content/RAFT e /content/RAFT/core a sys.path.\") from e\n",
    "\n",
    "        self.device = torch.device(device) if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.args = _DotArgs(small=small, mixed_precision=mixed_precision, alternate_corr=alternate_corr)\n",
    "        self.net = RAFTCore(self.args)\n",
    "\n",
    "        state = torch.load(weights, map_location='cpu')\n",
    "        if isinstance(state, dict) and 'state_dict' in state and isinstance(state['state_dict'], dict):\n",
    "            state = state['state_dict']\n",
    "        if isinstance(state, dict):\n",
    "            state = { (k.split('module.',1)[-1]): v for k,v in state.items() }\n",
    "\n",
    "        missing, unexpected = self.net.load_state_dict(state, strict=False)\n",
    "        if missing:    print(\"[RAFTAdapter] missing:\", len(missing))\n",
    "        if unexpected: print(\"[RAFTAdapter] unexpected:\", len(unexpected))\n",
    "\n",
    "        self.net.to(self.device).eval()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, im0, im1, iters:int=8):\n",
    "        from core.utils.utils import InputPadder\n",
    "        t0 = torch.from_numpy(im0.transpose(2,0,1)).float().unsqueeze(0)/255.0\n",
    "        t1 = torch.from_numpy(im1.transpose(2,0,1)).float().unsqueeze(0)/255.0\n",
    "        t0 = t0.to(self.device); t1 = t1.to(self.device)\n",
    "        padder = InputPadder(t0.shape)\n",
    "        t0p, t1p = padder.pad(t0, t1)\n",
    "        _, flow_up = self.net(t0p, t1p, iters=iters, test_mode=True)\n",
    "        flow = padder.unpad(flow_up)[0].permute(1,2,0).detach().cpu().numpy().astype('float32')\n",
    "        return flow\n",
    "\"\"\"))\n",
    "\n",
    "print(\"Framework creato in /content/oflow2d ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZA296H-AeDD"
   },
   "outputs": [],
   "source": [
    "# === RAFT: CONFIG + UTILS =====================================================\n",
    "\n",
    "import cv2, numpy as np, json, time, torch, os, pathlib\n",
    "from oflow2d.common.viz import flow_to_color\n",
    "\n",
    "# Config “di alto livello” per RAFT\n",
    "MAX_EDGE = 640      # 512 se vuoi più sicurezza, 768 se la GPU regge\n",
    "ITERS    = 8        # 6–12 in base alla qualità che vuoi\n",
    "VIZ_FPS  = None     # None = usa fps del video, oppure metti un numero (es. 25.0)\n",
    "SAVE_FLO = True     # salva anche i flow in formato .flo standard\n",
    "\n",
    "def resize_pair(f0, f1, max_edge=640):\n",
    "    \"\"\"\n",
    "    Ridimensiona la coppia di frame in modo che il lato max sia <= max_edge\n",
    "    e divisibile per 8 (richiesta tipica dei modelli di optical flow).\n",
    "    Ritorna: f0s, f1s, scale, (H_orig, W_orig)\n",
    "    \"\"\"\n",
    "    h, w = f0.shape[:2]\n",
    "    scale = min(1.0, max_edge / max(h, w))\n",
    "    if scale < 1.0:\n",
    "        new_w = int((w * scale) // 8 * 8)\n",
    "        new_h = int((h * scale) // 8 * 8)\n",
    "        f0s = cv2.resize(f0, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        f1s = cv2.resize(f1, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        return f0s, f1s, scale, (h, w)\n",
    "    return f0, f1, 1.0, (h, w)\n",
    "\n",
    "def upsample_flow(flow, orig_hw, scale):\n",
    "    \"\"\"\n",
    "    Porta il flow dalla risoluzione ridotta alla risoluzione originale,\n",
    "    correggendo anche la scala delle componenti (u,v).\n",
    "    \"\"\"\n",
    "    H, W = orig_hw\n",
    "    if scale != 1.0:\n",
    "        flow = cv2.resize(flow, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "        flow = flow / scale\n",
    "    return flow\n",
    "\n",
    "def save_flo(path, flow):\n",
    "    \"\"\"\n",
    "    Salva il flow nel formato .flo standard (PIEH header).\n",
    "    \"\"\"\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(b\"PIEH\")\n",
    "        np.array([flow.shape[1]], np.int32).tofile(f)  # width\n",
    "        np.array([flow.shape[0]], np.int32).tofile(f)  # height\n",
    "        flow.astype(np.float32).tofile(f)\n",
    "\n",
    "def video_fps(path, default=25.0):\n",
    "    \"\"\"\n",
    "    Legge l'FPS dal file video (fallback a default se non disponibile).\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or default\n",
    "    cap.release()\n",
    "    return float(fps) if fps and fps > 0 else default\n",
    "\n",
    "def process_video(in_path, out_dir, model,\n",
    "                  max_edge=MAX_EDGE, iters=ITERS,\n",
    "                  viz_fps=None, save_flo_flag=True):\n",
    "    \"\"\"\n",
    "    Esegue RAFT (o qualunque modello compatibile) su tutte le coppie di frame\n",
    "    di un video:\n",
    "      - legge il video\n",
    "      - calcola il flow frame-to-frame\n",
    "      - salva i flow (.npy + opzionale .flo)\n",
    "      - genera un mp4 di visualizzazione color-coded\n",
    "      - ritorna: (fps_modello, path_video_output)\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # 1) Leggi tutti i frame in RGB\n",
    "    cap = cv2.VideoCapture(in_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    cap.release()\n",
    "    assert len(frames) >= 2, \"Il video deve avere almeno 2 frame.\"\n",
    "\n",
    "    # 2) Loop sulle coppie consecutive\n",
    "    times = []\n",
    "    viz_frames = []\n",
    "    for i in range(len(frames) - 1):\n",
    "        f0, f1 = frames[i], frames[i + 1]\n",
    "        f0s, f1s, scale, orig_hw = resize_pair(f0, f1, max_edge)\n",
    "\n",
    "        t0 = time.time()\n",
    "        flow = model(f0s, f1s, iters=iters)          # RAFTAdapter(...)\n",
    "        times.append(time.time() - t0)\n",
    "\n",
    "        flow = upsample_flow(flow, orig_hw, scale)\n",
    "\n",
    "        # salva anche come .npy per analisi successive\n",
    "        np.save(f\"{out_dir}/flow_{i:06d}.npy\", flow)\n",
    "        if save_flo_flag:\n",
    "            save_flo(f\"{out_dir}/flow_{i:06d}.flo\", flow)\n",
    "\n",
    "        viz_frames.append(flow_to_color(flow))\n",
    "\n",
    "        if torch.cuda.is_available() and i % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # 3) Video di visualizzazione\n",
    "    fps_model = 1.0 / np.mean(times)\n",
    "    fps_out = viz_fps if viz_fps is not None else video_fps(in_path)\n",
    "\n",
    "    h, w, _ = viz_frames[0].shape\n",
    "    out_mp4 = f\"{out_dir}/flow_viz.mp4\"\n",
    "    vw = cv2.VideoWriter(\n",
    "        out_mp4,\n",
    "        cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "        fps_out,\n",
    "        (w, h),\n",
    "    )\n",
    "    for f in viz_frames:\n",
    "        vw.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
    "    vw.release()\n",
    "\n",
    "    # 4) Piccolo JSON con statistiche\n",
    "    with open(f\"{out_dir}/metrics.json\", \"w\") as f:\n",
    "        json.dump(\n",
    "            {\"pairs\": len(times), \"fps_model\": float(fps_model)},\n",
    "            f,\n",
    "            indent=2,\n",
    "        )\n",
    "\n",
    "    return fps_model, out_mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klT7DmIHAjQ_",
    "outputId": "d8b6bc5a-b4f9-4054-cb4d-2fe288d738e5"
   },
   "outputs": [],
   "source": [
    "# === RAFT: CREAZIONE MODELLO ==================================================\n",
    "6\n",
    "from oflow2d.adapters import make_model\n",
    "\n",
    "def create_raft_model():\n",
    "    \"\"\"\n",
    "    Crea un RAFTAdapter usando i pesi già scaricati in /content/RAFT/models.\n",
    "    Se trova il modello small usa quello, altrimenti usa il RAFT Sintel.\n",
    "    \"\"\"\n",
    "    weights_small = \"/content/RAFT/models/raft-small.pth\"\n",
    "    weights_std   = \"/content/RAFT/models/raft-sintel.pth\"\n",
    "    use_small = os.path.exists(weights_small)\n",
    "\n",
    "    model = make_model(\n",
    "        \"raft\",\n",
    "        weights        = (weights_small if use_small else weights_std),\n",
    "        small          = bool(use_small),\n",
    "        mixed_precision= True,    # FP16 → memoria più bassa\n",
    "        alternate_corr = False    # niente estensioni CUDA custom\n",
    "    )\n",
    "    print(\"RAFT model ready. small:\", use_small)\n",
    "    return model\n",
    "\n",
    "raft_model = create_raft_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "2MqE3TDQAn1X",
    "outputId": "4a829ec4-73c8-467d-b9df-6484ab31b61e"
   },
   "outputs": [],
   "source": [
    "# === RAFT: DEMO SU VIDEO CARICATI ============================================\n",
    "\n",
    "from google.colab import files\n",
    "from IPython.display import Video, display\n",
    "\n",
    "def run_raft_on_uploaded_videos(model,\n",
    "                                max_edge=MAX_EDGE,\n",
    "                                iters=ITERS,\n",
    "                                viz_fps=VIZ_FPS,\n",
    "                                save_flo=SAVE_FLO):\n",
    "    \"\"\"\n",
    "    - Apre il file picker di Colab\n",
    "    - Per ogni video caricato:\n",
    "        * lancia RAFT con process_video\n",
    "        * stampa FPS del modello\n",
    "        * mostra il video di flow\n",
    "    \"\"\"\n",
    "    uploaded = files.upload()  # seleziona uno o più .mp4/.mov/.mkv\n",
    "\n",
    "    os.makedirs(\"/content/outputs\", exist_ok=True)\n",
    "\n",
    "    for name in uploaded:\n",
    "        in_path = f\"/content/{name}\"\n",
    "        base = pathlib.Path(name).stem\n",
    "        out_dir = f\"/content/outputs/{base}_raft\"\n",
    "\n",
    "        fps, mp4 = process_video(\n",
    "            in_path, out_dir, model,\n",
    "            max_edge=max_edge,\n",
    "            iters=iters,\n",
    "            viz_fps=viz_fps,\n",
    "            save_flo_flag=save_flo,\n",
    "        )\n",
    "\n",
    "        print(f\"{name}  ->  FPS modello: {fps:.2f}  |  {mp4}\")\n",
    "        display(Video(mp4, embed=True))\n",
    "\n",
    "# lancia davvero la demo:\n",
    "run_raft_on_uploaded_videos(raft_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOu-gNV_2kYf",
    "outputId": "5212e1c0-26fe-4029-d9d7-bf4251efb7cd"
   },
   "outputs": [],
   "source": [
    "# SPyNet: prova PyPI, se fallisce usa la repo GitHub\n",
    "import sys, subprocess\n",
    "def pip_install(spec):\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-qU\", spec], check=True)\n",
    "\n",
    "try:\n",
    "    pip_install(\"spynet-pytorch\")\n",
    "    print(\"✓ spynet-pytorch da PyPI\")\n",
    "except Exception:\n",
    "    pip_install(\"git+https://github.com/Guillem96/spynet-pytorch\")\n",
    "    print(\"✓ spynet-pytorch da GitHub\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eF4tH4tQ2kWS",
    "outputId": "5c426b14-87d6-42f4-d25c-014769e2d37c"
   },
   "outputs": [],
   "source": [
    "# /content/oflow2d/adapters/spynet_pkg.py\n",
    "import pathlib, textwrap, importlib, shutil, os\n",
    "pathlib.Path(\"/content/oflow2d/adapters\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pathlib.Path(\"/content/oflow2d/adapters/spynet_pkg.py\").write_text(textwrap.dedent(\"\"\"\n",
    "import torch, numpy as np, torch.nn.functional as F\n",
    "\n",
    "def _to_tensor(img):\n",
    "    # img: HxWx3 uint8 RGB -> (1,3,H,W) float in [0,1]\n",
    "    t = torch.from_numpy(img).permute(2,0,1).float().div(255.0)\n",
    "    return t.unsqueeze(0)\n",
    "\n",
    "class SPyNetPkgAdapter:\n",
    "    def __init__(self, device=None, k: int = 5):\n",
    "        # Import dal pacchetto funzionante\n",
    "        try:\n",
    "            from spynet.model import SpyNet as Net\n",
    "        except Exception as e:\n",
    "            raise ImportError(\"Pacchetto 'spynet-pytorch' non importabile.\") from e\n",
    "\n",
    "        self.device = torch.device(device) if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # Istanzia con pesi pre-addestrati (le versioni differiscono leggermente, gestiamo i casi)\n",
    "        net = None\n",
    "        # Tentativi robusti\n",
    "        for attempt in (\n",
    "            lambda: Net(pretrained=True),\n",
    "            lambda: Net(k=k),            # crea i livelli e poi carichi tu i pesi se servisse\n",
    "        ):\n",
    "            try:\n",
    "                net = attempt()\n",
    "                break\n",
    "            except Exception:\n",
    "                pass\n",
    "        if net is None:\n",
    "            net = Net(k=k)\n",
    "\n",
    "        self.net = net.to(self.device).eval()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, im0, im1, iters=None):\n",
    "        t0 = _to_tensor(im0).to(self.device)\n",
    "        t1 = _to_tensor(im1).to(self.device)\n",
    "\n",
    "        # Alcune implementazioni richiedono multipli di 32\n",
    "        H, W = t0.shape[-2], t0.shape[-1]\n",
    "        Hp = (H + 31)//32*32; Wp = (W + 31)//32*32\n",
    "        pad = (0, Wp-W, 0, Hp-H)\n",
    "        t0p = F.pad(t0, pad, mode='replicate')\n",
    "        t1p = F.pad(t1, pad, mode='replicate')\n",
    "\n",
    "        # Forward: diverse firme → prova in ordine sicuro\n",
    "        out = None\n",
    "        try:\n",
    "            out = self.net([t0p, t1p], limit_k=-1)\n",
    "        except Exception:\n",
    "            try:\n",
    "                out = self.net([t0p, t1p])\n",
    "            except Exception:\n",
    "                try:\n",
    "                    out = self.net((t0p, t1p))\n",
    "                except Exception:\n",
    "                    out = self.net(t0p, t1p)\n",
    "\n",
    "        # Alcune versioni ritornano lista/tupla\n",
    "        if isinstance(out, (list, tuple)):\n",
    "            out = out[0]\n",
    "        # Taglia padding e converti a (H,W,2) float32\n",
    "        flow = out[:, :, :H, :W][0].permute(1,2,0).detach().cpu().numpy().astype(\"float32\")\n",
    "        return flow\n",
    "\"\"\"))\n",
    "\n",
    "# Aggiorna il factory del framework per includere 'spynet_pkg'\n",
    "factory = \"/content/oflow2d/adapters/__init__.py\"\n",
    "if not os.path.exists(factory) or \"spynet_pkg\" not in open(factory, \"r\").read():\n",
    "    open(factory, \"w\").write(\"\"\"\n",
    "def make_model(name: str, **kwargs):\n",
    "    name = name.lower()\n",
    "    if name == 'raft':\n",
    "        from .raft import RAFTAdapter\n",
    "        return RAFTAdapter(**kwargs)\n",
    "    if name in ('spynet', 'spynet_pkg', 'spynet-niklaus'):\n",
    "        from .spynet_pkg import SPyNetPkgAdapter\n",
    "        return SPyNetPkgAdapter(**kwargs)\n",
    "    raise ValueError(f\"Modello '{name}' non supportato. Usa 'raft' o 'spynet'.\")\n",
    "\"\"\")\n",
    "\n",
    "# pulisci cache py e ricarica\n",
    "shutil.rmtree(\"/content/oflow2d/__pycache__\", ignore_errors=True)\n",
    "shutil.rmtree(\"/content/oflow2d/adapters/__pycache__\", ignore_errors=True)\n",
    "import oflow2d.adapters as adapters; importlib.reload(adapters)\n",
    "print(\"Adapter SPyNetPkg scritto e factory aggiornato ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8fmTze8ExYE",
    "outputId": "c579e0fd-4953-4c18-eb6b-0fff9c58733b"
   },
   "outputs": [],
   "source": [
    "# === SPyNet: CREAZIONE MODELLO + SMOKE TEST ===================================\n",
    "\n",
    "import numpy as np\n",
    "from oflow2d.adapters import make_model\n",
    "\n",
    "def create_spynet_model(device=None):\n",
    "    \"\"\"\n",
    "    Crea un SPyNetPkgAdapter tramite la factory make_model('spynet').\n",
    "    Esegue anche uno smoke test su due frame finti per verificare che funzioni.\n",
    "    \"\"\"\n",
    "    cfg = {}\n",
    "    if device is not None:\n",
    "        cfg[\"device\"] = device\n",
    "\n",
    "    spynet = make_model(\"spynet\", **cfg)\n",
    "    print(\"SPyNet model ready.\")\n",
    "\n",
    "    # --- smoke test minimale ---\n",
    "    a = np.zeros((240, 320, 3), np.uint8)\n",
    "    b = a.copy()\n",
    "    b[:, :10] = 255  # banda bianca per avere un po' di movimento\n",
    "    f = spynet(a, b, iters=None)\n",
    "    print(\"Smoke test SPyNet:\", f.shape, f.dtype, np.isfinite(f).all())\n",
    "\n",
    "    return spynet\n",
    "\n",
    "spynet_model = create_spynet_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "aK5UgK1HE6kO",
    "outputId": "1c2f2abc-098a-484c-cf79-6db94eea42e7"
   },
   "outputs": [],
   "source": [
    "# === SPyNet: DEMO SU VIDEO CARICATI ===========================================\n",
    "\n",
    "from google.colab import files\n",
    "from IPython.display import Video, display\n",
    "import pathlib, os\n",
    "\n",
    "def run_spynet_on_uploaded_videos(model,\n",
    "                                  max_edge=MAX_EDGE,\n",
    "                                  iters=ITERS,\n",
    "                                  viz_fps=VIZ_FPS,\n",
    "                                  save_flo=SAVE_FLO):\n",
    "    \"\"\"\n",
    "    - Apre il file picker di Colab\n",
    "    - Per ogni video caricato:\n",
    "        * lancia SPyNet usando process_video(...)\n",
    "        * stampa FPS del modello\n",
    "        * mostra il video di flow color-coded\n",
    "    \"\"\"\n",
    "    uploaded = files.upload()  # seleziona uno o più video dal tuo PC\n",
    "\n",
    "    os.makedirs(\"/content/outputs_spynet\", exist_ok=True)\n",
    "\n",
    "    for name in uploaded:\n",
    "        vp = f\"/content/{name}\"\n",
    "        base = pathlib.Path(name).stem\n",
    "        out_dir = f\"/content/outputs_spynet/{base}_SPyNet\"\n",
    "\n",
    "        fps, mp4 = process_video(\n",
    "            vp,\n",
    "            out_dir,\n",
    "            model,\n",
    "            max_edge=max_edge,\n",
    "            iters=iters,\n",
    "            viz_fps=viz_fps,\n",
    "            save_flo_flag=save_flo,\n",
    "        )\n",
    "\n",
    "        print(f\"[SPyNet] {name} -> {fps:.2f} FPS  |  {mp4}\")\n",
    "        display(Video(mp4, embed=True))\n",
    "\n",
    "# lancia davvero la demo SPyNet:\n",
    "run_spynet_on_uploaded_videos(spynet_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cgx0seZIP50",
    "outputId": "26c273fa-9d37-4f27-bd47-8587710433e4"
   },
   "outputs": [],
   "source": [
    "# === FlowNet2: deps in un site isolato =======================================\n",
    "FLOW_SITE = \"/content/_flow_site\"\n",
    "\n",
    "# crea la cartella e installa i pacchetti pin\n",
    "!mkdir -p \"$FLOW_SITE\"\n",
    "!python -m pip install -q -t \"$FLOW_SITE\" \\\n",
    "  \"numpy==1.26.4\" \"scipy==1.11.4\" \\\n",
    "  \"torchmetrics==1.3.2\" \"lightning>=2,<2.5\" \\\n",
    "  \"opencv-python-headless==4.8.1.78\" \"loguru>=0.7\" \"jsonargparse>=4.27\" \\\n",
    "  \"requests==2.31\" \"einops>=0.6\" \"ptlflow==0.4.1\" \"timm>=0.9.12\"\n",
    "\n",
    "# aggiunge il site isolato al PYTHONPATH corrente\n",
    "import site, importlib.util\n",
    "site.addsitedir(FLOW_SITE)\n",
    "\n",
    "import ptlflow\n",
    "print(\"ptlflow visibile?\", importlib.util.find_spec(\"ptlflow\") is not None)\n",
    "print(\"PTLFlow version:\", getattr(ptlflow, \"__version__\", \"unknown\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb5GHBgbISDn"
   },
   "outputs": [],
   "source": [
    "# === Context manager: aggiunge/rimuove il path di FlowNet2 temporaneamente ===\n",
    "import sys, contextlib\n",
    "\n",
    "FLOW_SITE = \"/content/_flow_site\"\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def use_flow_site():\n",
    "    sys.path.insert(0, FLOW_SITE)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        if FLOW_SITE in sys.path:\n",
    "            sys.path.remove(FLOW_SITE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsb5GgR4ISBI",
    "outputId": "20ca0232-e6c3-4d7f-9e5d-ffb7ac108a79"
   },
   "outputs": [],
   "source": [
    "# === FlowNet2Adapter + factory make_model (RAFT, SPyNet, FlowNet2) ===========\n",
    "import os, textwrap, pathlib, importlib, shutil\n",
    "\n",
    "base = \"/content/oflow2d\"\n",
    "adp  = f\"{base}/adapters\"\n",
    "os.makedirs(adp, exist_ok=True)\n",
    "open(f\"{base}/__init__.py\", \"a\").close()\n",
    "open(f\"{adp}/__init__.py\", \"a\").close()\n",
    "\n",
    "adapter_code = f\"\"\"\n",
    "import torch, numpy as np\n",
    "\n",
    "# userà il context manager definito nel notebook (importato da __main__)\n",
    "try:\n",
    "    from __main__ import use_flow_site\n",
    "except Exception:\n",
    "    import sys\n",
    "    FLOW_SITE = '{\"/content/_flow_site\"}'\n",
    "    def use_flow_site():\n",
    "        class _Ctx:\n",
    "            def __enter__(self):\n",
    "                sys.path.insert(0, FLOW_SITE)\n",
    "            def __exit__(self, *args):\n",
    "                if FLOW_SITE in sys.path:\n",
    "                    sys.path.remove(FLOW_SITE)\n",
    "        return _Ctx()\n",
    "\n",
    "class FlowNet2Adapter:\n",
    "    def __init__(self, device=None, ckpt=\"things\"):\n",
    "        self.device = torch.device(device) if device else torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        with use_flow_site():\n",
    "            import ptlflow\n",
    "            from ptlflow.utils.io_adapter import IOAdapter\n",
    "            self._ptlflow = ptlflow\n",
    "            self.model = ptlflow.get_model(\"flownet2\", ckpt_path=ckpt).to(self.device).eval()\n",
    "            self.IOAdapter = IOAdapter\n",
    "        self._io = None\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def __call__(self, img0_uint8, img1_uint8, iters=None):\n",
    "        \\\"\\\"\\\"img0_uint8, img1_uint8: HxWx3 uint8 (RGB o BGR, basta che siano coerenti).\n",
    "        Ritorna: flow HxWx2 float32.\n",
    "        \\\"\\\"\\\"\n",
    "        assert img0_uint8.dtype == np.uint8 and img1_uint8.dtype == np.uint8\n",
    "        h, w = img0_uint8.shape[:2]\n",
    "\n",
    "        if self._io is None:\n",
    "            with use_flow_site():\n",
    "                self._io = self.IOAdapter(self.model, (h, w))\n",
    "\n",
    "        with use_flow_site():\n",
    "            inputs = self._io.prepare_inputs([img0_uint8, img1_uint8])  # {{'images': (1,2,3,H,W)}}\n",
    "        for k in inputs:\n",
    "            inputs[k] = inputs[k].to(self.device, non_blocking=True)\n",
    "\n",
    "        with use_flow_site():\n",
    "            preds = self.model(inputs)\n",
    "\n",
    "        flows = preds.get(\"flows\", preds.get(\"flow\", None))\n",
    "        if flows is None:\n",
    "            raise RuntimeError(\"PTLFlow: output 'flows'/'flow' non trovato.\")\n",
    "        ft = flows[-1] if isinstance(flows, (list, tuple)) else flows\n",
    "        if ft.dim() == 5:  # (B,1,2,H,W) -> (B,2,H,W)\n",
    "            ft = ft[:, 0]\n",
    "        flow = ft[0].permute(1, 2, 0).detach().cpu().float().numpy()\n",
    "        return flow  # HxWx2 float32\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{adp}/flownet2_adapter.py\", \"w\") as f:\n",
    "    f.write(textwrap.dedent(adapter_code))\n",
    "print(\"Scritto:\", f\"{adp}/flownet2_adapter.py\")\n",
    "\n",
    "# Factory unica RAFT + SPyNet + FlowNet2\n",
    "from pathlib import Path\n",
    "\n",
    "Path(f\"{adp}/__init__.py\").write_text(r\"\"\"\n",
    "def make_model(name: str, **kwargs):\n",
    "    name = (name or \"\").lower()\n",
    "\n",
    "    if name in (\"raft\", \"raft_small\", \"raft_sintel\"):\n",
    "        from .raft import RAFTAdapter\n",
    "        return RAFTAdapter(**kwargs)\n",
    "\n",
    "    if name in (\"spynet\", \"spynet_pkg\", \"spynet-niklaus\", \"spy\"):\n",
    "        try:\n",
    "            from .spynet_adapter import SPyNetAdapter\n",
    "            return SPyNetAdapter(**kwargs)\n",
    "        except Exception:\n",
    "            from .spynet_pkg import SPyNetPkgAdapter\n",
    "            return SPyNetPkgAdapter(**kwargs)\n",
    "\n",
    "    if name in (\"flownet2\", \"flownet\", \"fn2\"):\n",
    "        from .flownet2_adapter import FlowNet2Adapter\n",
    "        return FlowNet2Adapter(**kwargs)\n",
    "\n",
    "    raise ValueError(f\"Modello '{name}' non supportato: {name}\")\n",
    "\"\"\")\n",
    "print(\"Factory aggiornata (RAFT, SPyNet, FlowNet2).\")\n",
    "\n",
    "# pulisci cache py e ricarica il modulo adapters\n",
    "shutil.rmtree(f\"{base}/__pycache__\", ignore_errors=True)\n",
    "shutil.rmtree(f\"{adp}/__pycache__\", ignore_errors=True)\n",
    "\n",
    "import oflow2d.adapters as adapters\n",
    "importlib.reload(adapters)\n",
    "print(\"Modulo oflow2d.adapters ricaricato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKQ1BdRbIR6M",
    "outputId": "a97fc373-042a-487d-8e53-e29d471d97f3"
   },
   "outputs": [],
   "source": [
    "# === FlowNet2: creazione modello + smoke test ================================\n",
    "import numpy as np, torch\n",
    "from oflow2d.adapters import make_model\n",
    "\n",
    "def create_flownet2_model(device=None, ckpt=\"things\"):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model = make_model(\"flownet2\", device=device, ckpt=ckpt)\n",
    "    print(f\"FlowNet2 model ready on {device}, ckpt={ckpt}\")\n",
    "\n",
    "    # Smoke test veloce\n",
    "    a = np.zeros((240, 320, 3), np.uint8)\n",
    "    b = a.copy()\n",
    "    b[:, 15:] = 255\n",
    "    flow = model(a, b)\n",
    "    print(\"Smoke FlowNet2:\", flow.shape, flow.dtype, np.isfinite(flow).all())\n",
    "\n",
    "    return model\n",
    "\n",
    "flownet2_model = create_flownet2_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "QAMV_s7yIR4K",
    "outputId": "01364ba2-fe3a-480c-84ef-d1748aca98bd"
   },
   "outputs": [],
   "source": [
    "# === FlowNet2: DEMO SU VIDEO CARICATI (solo flow color-coded) ================\n",
    "from google.colab import files\n",
    "from IPython.display import Video, display\n",
    "import pathlib, os\n",
    "\n",
    "def run_flownet2_on_uploaded_videos(model,\n",
    "                                    max_edge=MAX_EDGE,\n",
    "                                    iters=ITERS,      # non usato da FlowNet2 ma compatibile con process_video\n",
    "                                    viz_fps=VIZ_FPS,\n",
    "                                    save_flo=SAVE_FLO):\n",
    "    \"\"\"\n",
    "    - Apre il file picker di Colab\n",
    "    - Per ogni video caricato:\n",
    "        * lancia FlowNet2 con process_video(...)\n",
    "        * stampa FPS del modello\n",
    "        * mostra il video di flow (unico output)\n",
    "    \"\"\"\n",
    "    uploaded = files.upload()  # scegli uno o più video dal tuo PC\n",
    "\n",
    "    os.makedirs(\"/content/outputs_flownet2\", exist_ok=True)\n",
    "\n",
    "    for name in uploaded:\n",
    "        vp = f\"/content/{name}\"\n",
    "        base = pathlib.Path(name).stem\n",
    "        out_dir = f\"/content/outputs_flownet2/{base}_FlowNet2\"\n",
    "\n",
    "        fps, mp4 = process_video(\n",
    "            vp,\n",
    "            out_dir,\n",
    "            model,\n",
    "            max_edge=max_edge,\n",
    "            iters=iters,\n",
    "            viz_fps=viz_fps,\n",
    "            save_flo_flag=save_flo,\n",
    "        )\n",
    "\n",
    "        print(f\"[FlowNet2] {name} -> {fps:.2f} FPS  |  {mp4}\")\n",
    "        display(Video(mp4, embed=True))\n",
    "\n",
    "# LANCIA LA DEMO\n",
    "run_flownet2_on_uploaded_videos(flownet2_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fSqke4_LoXg",
    "outputId": "4ee64c0e-daf7-48a0-aff9-291c3c793f35"
   },
   "outputs": [],
   "source": [
    "# === PWCNetAdapter basato su PTLFlow (solo flow) =============================\n",
    "import os, textwrap, pathlib, importlib, shutil\n",
    "\n",
    "base = \"/content/oflow2d\"\n",
    "adp  = f\"{base}/adapters\"\n",
    "os.makedirs(adp, exist_ok=True)\n",
    "pathlib.Path(f\"{base}/__init__.py\").touch()\n",
    "pathlib.Path(f\"{adp}/__init__.py\").touch()\n",
    "\n",
    "pwc_code = r'''\n",
    "import torch, numpy as np\n",
    "\n",
    "# usa il context manager del notebook per caricare PTLFlow dal site isolato\n",
    "try:\n",
    "    from __main__ import use_flow_site\n",
    "except Exception:\n",
    "    import sys\n",
    "    FLOW_SITE = \"/content/_flow_site\"\n",
    "    def use_flow_site():\n",
    "        class _Ctx:\n",
    "            def __enter__(self):\n",
    "                sys.path.insert(0, FLOW_SITE)\n",
    "            def __exit__(self, *a):\n",
    "                if FLOW_SITE in sys.path:\n",
    "                    sys.path.remove(FLOW_SITE)\n",
    "        return _Ctx()\n",
    "\n",
    "class PWCNetAdapter:\n",
    "    def __init__(self, device=None, ckpt=\"things\"):\n",
    "        self.device = torch.device(device) if device else torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        with use_flow_site():\n",
    "            import ptlflow\n",
    "            last_err = None\n",
    "            # prova alcuni nomi comuni\n",
    "            for name in (\"pwcnet\", \"pwc\"):\n",
    "                try:\n",
    "                    self.model = ptlflow.get_model(name, ckpt_path=ckpt).to(self.device).eval()\n",
    "                    self._model_name = name\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    last_err = e\n",
    "            if not hasattr(self, \"model\"):\n",
    "                raise RuntimeError(\n",
    "                    f\"PWCNet non trovato in PTLFlow: {type(last_err).__name__}: {last_err}\"\n",
    "                )\n",
    "\n",
    "            from ptlflow.utils.io_adapter import IOAdapter\n",
    "            self.IOAdapter = IOAdapter\n",
    "\n",
    "        self._io = None\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def __call__(self, img0_uint8, img1_uint8, iters=None):\n",
    "        \"\"\"img0_uint8, img1_uint8: HxWx3 uint8 (RGB o BGR, ma coerenti).\n",
    "        Ritorna: flow HxWx2 float32.\n",
    "        \"\"\"\n",
    "        assert img0_uint8.dtype == np.uint8 and img1_uint8.dtype == np.uint8, \\\n",
    "            \"Servono frame uint8\"\n",
    "\n",
    "        h, w = img0_uint8.shape[:2]\n",
    "\n",
    "        if self._io is None:\n",
    "            with use_flow_site():\n",
    "                self._io = self.IOAdapter(self.model, (h, w))\n",
    "\n",
    "        with use_flow_site():\n",
    "            x = self._io.prepare_inputs([img0_uint8, img1_uint8])  # {'images': (1,2,3,H,W)}\n",
    "            for k in x:\n",
    "                x[k] = x[k].to(self.device, non_blocking=True)\n",
    "            preds = self.model(x)\n",
    "\n",
    "        flows = preds.get(\"flows\", preds.get(\"flow\", None))\n",
    "        if flows is None:\n",
    "            raise RuntimeError(\"PTLFlow/PWCNet: output 'flows'/'flow' non trovato.\")\n",
    "\n",
    "        ft = flows[-1] if isinstance(flows, (list, tuple)) else flows\n",
    "        if ft.dim() == 5:   # (B,1,2,H,W) -> (B,2,H,W)\n",
    "            ft = ft[:, 0]\n",
    "\n",
    "        flow = ft[0].permute(1, 2, 0).detach().cpu().float().numpy()  # HxWx2\n",
    "        return flow\n",
    "'''\n",
    "\n",
    "open(f\"{adp}/pwcnet_adapter.py\",\"w\").write(textwrap.dedent(pwc_code))\n",
    "print(\"Scritto:\", f\"{adp}/pwcnet_adapter.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBN8RxBMLoWM",
    "outputId": "a12486d6-4193-4d19-f976-425c1cacb94a"
   },
   "outputs": [],
   "source": [
    "# === Factory make_model unica (RAFT, SPyNet, FlowNet2, PWCNet) ===============\n",
    "from pathlib import Path\n",
    "\n",
    "adp = \"/content/oflow2d/adapters\"\n",
    "\n",
    "factory_txt = r\"\"\"\n",
    "def make_model(name: str, **kwargs):\n",
    "    name = (name or \"\").lower()\n",
    "\n",
    "    # RAFT -------------------------------------------------------------\n",
    "    if name in (\"raft\", \"raft_small\", \"raft_sintel\"):\n",
    "        from .raft import RAFTAdapter\n",
    "        return RAFTAdapter(**kwargs)\n",
    "\n",
    "    # SPyNet -----------------------------------------------------------\n",
    "    if name in (\"spynet\", \"spynet_pkg\", \"spynet-niklaus\", \"spy\"):\n",
    "        try:\n",
    "            from .spynet_adapter import SPyNetAdapter\n",
    "            return SPyNetAdapter(**kwargs)\n",
    "        except Exception:\n",
    "            from .spynet_pkg import SPyNetPkgAdapter\n",
    "            return SPyNetPkgAdapter(**kwargs)\n",
    "\n",
    "    # FlowNet2 ---------------------------------------------------------\n",
    "    if name in (\"flownet2\", \"flownet\", \"fn2\"):\n",
    "        from .flownet2_adapter import FlowNet2Adapter\n",
    "        return FlowNet2Adapter(**kwargs)\n",
    "\n",
    "    # PWC-Net ----------------------------------------------------------\n",
    "    if name in (\"pwcnet\", \"pwc\", \"pwc-net\"):\n",
    "        from .pwcnet_adapter import PWCNetAdapter\n",
    "        return PWCNetAdapter(**kwargs)\n",
    "\n",
    "    raise ValueError(f\"Modello '{name}' non supportato: {name}\")\n",
    "\"\"\"\n",
    "\n",
    "Path(f\"{adp}/__init__.py\").write_text(factory_txt)\n",
    "print(\"Factory adapters riscritta.\")\n",
    "\n",
    "# pulisci cache e ricarica il modulo adapters\n",
    "import shutil, importlib\n",
    "shutil.rmtree(\"/content/oflow2d/__pycache__\", ignore_errors=True)\n",
    "shutil.rmtree(\"/content/oflow2d/adapters/__pycache__\", ignore_errors=True)\n",
    "\n",
    "import oflow2d.adapters as adapters\n",
    "importlib.reload(adapters)\n",
    "print(\"Modulo oflow2d.adapters ricaricato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ey6tbGaULoSv",
    "outputId": "cf46aba6-c39a-41ca-ad46-51fda478b77a"
   },
   "outputs": [],
   "source": [
    "# === PWCNet: creazione modello + smoke test ==================================\n",
    "import numpy as np, torch\n",
    "from oflow2d.adapters import make_model\n",
    "\n",
    "def create_pwcnet_model(device=None, ckpt=\"things\"):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model = make_model(\"pwcnet\", device=device, ckpt=ckpt)\n",
    "    print(f\"PWCNet model ready on {device}, ckpt={ckpt}\")\n",
    "\n",
    "    # smoke test veloce\n",
    "    a = np.zeros((240, 320, 3), np.uint8)\n",
    "    b = a.copy()\n",
    "    b[:, 15:] = 255\n",
    "    flow = model(a, b)\n",
    "    print(\"Smoke PWCNet:\", flow.shape, flow.dtype, np.isfinite(flow).all())\n",
    "\n",
    "    return model\n",
    "\n",
    "pwcnet_model = create_pwcnet_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "NjHJijApLoQv",
    "outputId": "4b66174f-141f-4340-d0e0-33a07fcd3568"
   },
   "outputs": [],
   "source": [
    "# === PWCNet: DEMO SU VIDEO CARICATI (solo flow color-coded) ==================\n",
    "from google.colab import files\n",
    "from IPython.display import Video, display\n",
    "import pathlib, os\n",
    "\n",
    "def run_pwcnet_on_uploaded_videos(model,\n",
    "                                  max_edge=MAX_EDGE,\n",
    "                                  iters=ITERS,      # non usato da PTLFlow ma ok per compatibilità\n",
    "                                  viz_fps=VIZ_FPS,\n",
    "                                  save_flo=SAVE_FLO):\n",
    "    \"\"\"\n",
    "    - Apre il file picker di Colab\n",
    "    - Per ogni video caricato:\n",
    "        * lancia PWCNet con process_video(...)\n",
    "        * stampa FPS del modello\n",
    "        * mostra il video di flow (unico output)\n",
    "    \"\"\"\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    os.makedirs(\"/content/outputs_pwcnet\", exist_ok=True)\n",
    "\n",
    "    for name in uploaded:\n",
    "        vp = f\"/content/{name}\"\n",
    "        base = pathlib.Path(name).stem\n",
    "        out_dir = f\"/content/outputs_pwcnet/{base}_PWCNet\"\n",
    "\n",
    "        fps, mp4 = process_video(\n",
    "            vp,\n",
    "            out_dir,\n",
    "            model,\n",
    "            max_edge=max_edge,\n",
    "            iters=iters,\n",
    "            viz_fps=viz_fps,\n",
    "            save_flo_flag=save_flo,\n",
    "        )\n",
    "\n",
    "        print(f\"[PWCNet] {name} -> {fps:.2f} FPS  |  {mp4}\")\n",
    "        display(Video(mp4, embed=True))\n",
    "\n",
    "# LANCIA LA DEMO\n",
    "run_pwcnet_on_uploaded_videos(pwcnet_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSxORMBaLoOp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "923ZDEMZLoMH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EOACxfPLoKU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCP2AYkXLoIh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZjyNRrYLoFE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKIx0gSpMvyD"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_0khdYWbnJE",
    "outputId": "aecccd67-5ea6-4033-e579-57ca510cefad"
   },
   "outputs": [],
   "source": [
    "import pathlib, textwrap\n",
    "base = pathlib.Path(\"/content/oflow2d\")\n",
    "(base/\"pipelines\").mkdir(parents=True, exist_ok=True)\n",
    "(open(base/\"pipelines\"/\"__init__.py\",\"a\")).close()\n",
    "\n",
    "path = base/\"pipelines\"/\"video_demo.py\"\n",
    "path.write_text(textwrap.dedent(\"\"\"\n",
    "import os, json, time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from oflow2d.common.viz import flow_to_color\n",
    "from oflow2d.adapters import make_model\n",
    "\n",
    "# default uguali al notebook\n",
    "MAX_EDGE = 640\n",
    "ITERS    = 8\n",
    "VIZ_FPS  = None\n",
    "SAVE_FLO = True\n",
    "\n",
    "def resize_pair(f0, f1, max_edge=MAX_EDGE):\n",
    "    h, w = f0.shape[:2]\n",
    "    scale = min(1.0, max_edge / max(h, w))\n",
    "    if scale < 1.0:\n",
    "        new_w = int((w * scale) // 8 * 8)\n",
    "        new_h = int((h * scale) // 8 * 8)\n",
    "        f0s = cv2.resize(f0, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        f1s = cv2.resize(f1, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        return f0s, f1s, scale, (h, w)\n",
    "    return f0, f1, 1.0, (h, w)\n",
    "\n",
    "def upsample_flow(flow, orig_hw, scale):\n",
    "    H, W = orig_hw\n",
    "    if scale != 1.0:\n",
    "        flow = cv2.resize(flow, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "        flow = flow / scale\n",
    "    return flow\n",
    "\n",
    "def save_flo(path, flow):\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(b\"PIEH\")\n",
    "        np.array([flow.shape[1]], np.int32).tofile(f)  # width\n",
    "        np.array([flow.shape[0]], np.int32).tofile(f)  # height\n",
    "        flow.astype(np.float32).tofile(f)\n",
    "\n",
    "def video_fps(path, default=25.0):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or default\n",
    "    cap.release()\n",
    "    return float(fps) if fps and fps > 0 else default\n",
    "\n",
    "def process_video(in_path, out_dir, model,\n",
    "                  max_edge=MAX_EDGE, iters=ITERS,\n",
    "                  viz_fps=VIZ_FPS, save_flo_flag=SAVE_FLO):\n",
    "    \\\"\\\"\\\"Video → modello → flow + video color-coded.\n",
    "    Ritorna (fps_modello, path_mp4).\n",
    "    \\\"\\\"\\\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(in_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    cap.release()\n",
    "    assert len(frames) >= 2, \"Il video deve avere almeno 2 frame.\"\n",
    "\n",
    "    times = []\n",
    "    viz_frames = []\n",
    "    for i in range(len(frames) - 1):\n",
    "        f0, f1 = frames[i], frames[i+1]\n",
    "        f0s, f1s, scale, orig_hw = resize_pair(f0, f1, max_edge=max_edge)\n",
    "\n",
    "        t0 = time.time()\n",
    "        flow = model(f0s, f1s, iters=iters)\n",
    "        times.append(time.time() - t0)\n",
    "\n",
    "        flow = upsample_flow(flow, orig_hw, scale)\n",
    "\n",
    "        np.save(os.path.join(out_dir, f\"flow_{i:06d}.npy\"), flow)\n",
    "        if save_flo_flag:\n",
    "            save_flo(os.path.join(out_dir, f\"flow_{i:06d}.flo\"), flow)\n",
    "\n",
    "        viz_frames.append(flow_to_color(flow))\n",
    "\n",
    "        if torch.cuda.is_available() and i % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    fps_model = 1.0 / np.mean(times)\n",
    "    fps_out = viz_fps if viz_fps is not None else video_fps(in_path)\n",
    "\n",
    "    h, w, _ = viz_frames[0].shape\n",
    "    out_mp4 = os.path.join(out_dir, \"flow_viz.mp4\")\n",
    "    vw = cv2.VideoWriter(\n",
    "        out_mp4,\n",
    "        cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "        fps_out,\n",
    "        (w, h),\n",
    "    )\n",
    "    for f in viz_frames:\n",
    "        vw.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
    "    vw.release()\n",
    "\n",
    "    with open(os.path.join(out_dir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump({\"pairs\": len(times), \"fps_model\": float(fps_model)}, f, indent=2)\n",
    "\n",
    "    return fps_model, out_mp4\n",
    "\n",
    "# --------- wrapper per creare i modelli -------------------------------------\n",
    "\n",
    "def create_raft_model():\n",
    "    weights_small = \"/content/RAFT/models/raft-small.pth\"\n",
    "    weights_std   = \"/content/RAFT/models/raft-sintel.pth\"\n",
    "    use_small = os.path.exists(weights_small)\n",
    "    model = make_model(\n",
    "        \"raft\",\n",
    "        weights=(weights_small if use_small else weights_std),\n",
    "        small=bool(use_small),\n",
    "        mixed_precision=True,\n",
    "        alternate_corr=False,\n",
    "    )\n",
    "    print(\"RAFT model ready. small:\", use_small)\n",
    "    return model\n",
    "\n",
    "def create_spynet_model(device=None):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = make_model(\"spynet\", device=device)\n",
    "    print(\"SPyNet model ready on\", device)\n",
    "    return model\n",
    "\n",
    "def create_flownet2_model(device=None, ckpt=\"things\"):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = make_model(\"flownet2\", device=device, ckpt=ckpt)\n",
    "    print(\"FlowNet2 model ready on\", device, \"ckpt=\", ckpt)\n",
    "    return model\n",
    "\n",
    "def create_pwcnet_model(device=None, ckpt=\"things\"):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = make_model(\"pwcnet\", device=device, ckpt=ckpt)\n",
    "    print(\"PWCNet model ready on\", device, \"ckpt=\", ckpt)\n",
    "    return model\n",
    "\"\"\"))\n",
    "print(\"Scritto /content/oflow2d/pipelines/video_demo.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkD5KX2cfIKM",
    "outputId": "cea2149c-bd54-46be-a88a-1f0e5eaaac9b"
   },
   "outputs": [],
   "source": [
    "!cd /content && zip -r oflow2d.zip oflow2d\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
